{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "This describes the first bigger programming project in the course, devoted to artificial\n",
    "neural networks.\n",
    "Application: Recognizing handwritten numbers\n",
    "Most people effortlessly recognise these digits as 504192. This ease is deceptive. The\n",
    "difficulty of visual pattern recognition becomes obvious when trying to write a computer\n",
    "program to recognise digits like the above. What seems easy when we do it ourselves\n",
    "suddenly becomes extremely difficult. Simple notions about how we recognise shapes -\n",
    "“a 9 has a loop at the top and a vertical line at the bottom right” - turn out to be not\n",
    "so easy to express algorithmically. If you try to specify such rules, you quickly get lost\n",
    "in a quagmire of exceptions, restrictions and special cases. It seems hopeless.\n",
    "Neural networks approach the problem differently. The idea is to use a large number of\n",
    "handwritten digits, called training examples, and then develop a system that can learn\n",
    "from these training examples. In other words, the neural network uses the examples to\n",
    "automatically derive rules for recognising handwritten digits. In addition, by increasing\n",
    "the number of training examples, the network can learn more about handwriting and\n",
    "thus improve its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement a feedforward neural network (as a class) consisting of 3 layers (input,\n",
    "hidden, output layer), where each layer can contain any number of neurons. Use\n",
    "the sigmoid function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward NN Class\n",
    "class FeedForwardNeuralNetwork():\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.weights_input_hidden = np.random.rand(self.input_size, self.hidden_size)\n",
    "        self.bias_hidden = np.random.rand(self.hidden_size)\n",
    "        self.weights_output_hidden = np.random.rand(self.hidden_size, self.output_size)\n",
    "        self.bias_output = np.random.rand(self.output_size)\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        hidden_input = np.dot(input_data, self.weights_input_hidden) + self.bias_hidden\n",
    "        hidden_output = self.sigmoid(hidden_input)\n",
    "\n",
    "        output = np.dot(hidden_output, self.weights_output_hidden) + self.bias_output\n",
    "        network_output = self.sigmoid(output)\n",
    "\n",
    "        return network_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Reading in MNIST data (provided in canvas). The data is separated into training\n",
    "data (50 000), validation data (10 000), and test data (10 000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data from mnist.pkl\n",
    "with open('mnist.pkl', 'rb') as f:\n",
    "    mnist_data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Extract training, validation, and test sets\n",
    "train_data, valid_data, test_data = mnist_data\n",
    "\n",
    "# Unpack the data into inputs and labels\n",
    "X_train, Y_train = train_data\n",
    "X_val, Y_val = valid_data\n",
    "X_test, Y_test = test_data\n",
    "\n",
    "# Convert inputs to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Implement the stochastic gradient method (SGD) to train the network. The implementation of the SGD should allow for different mini-batch sizes and different\n",
    "numbers of epochs. An epoch is the complete pass of the training data through\n",
    "the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Implement the backpropagation algorithm (used in SGD to effectively calculate\n",
    "the derivative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprogation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Train and test the accuracy of the network for the following parameters:\n",
    "• Input layer with 784 + 1 neurons\n",
    "• hidden layer with 30 + 1 neurons\n",
    "• Output layer with 10 neurons\n",
    "As loss function use the quadratic function (square loss),\n",
    "where (x, y) is a pair of training data, n the amount of used training data, and hw\n",
    "represents the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Print an output of the learning success per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LR success per epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
